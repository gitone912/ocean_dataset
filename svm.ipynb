{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_path = '/Users/pranaymishra/Desktop/ml_practice/ocean_dataset/cleaned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_img_path = '/Users/pranaymishra/Desktop/ml_practice/ocean_dataset/polluted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io, color, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "from skimage import color, feature\n",
    "\n",
    "def load_images_and_labels(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(folder, filename)\n",
    "            \n",
    "            # Omit pilmode argument when using PyAV plugin\n",
    "            img = imageio.imread(image_path)\n",
    "            \n",
    "            if img.shape[2] == 4:  # Check if image has 4 channels (RGBA)\n",
    "                img = color.rgba2rgb(img)\n",
    "            \n",
    "            img = color.rgb2gray(img)\n",
    "            hog_features = feature.hog(img)\n",
    "            images.append(hog_features)\n",
    "            labels.append(label)\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/srwhm0y53j14k9ypbh_kj7v40000gn/T/ipykernel_20253/2473183843.py:13: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(image_path)\n"
     ]
    }
   ],
   "source": [
    "polluted_images, polluted_labels = load_images_and_labels(cleaned_path, 1)\n",
    "cleaned_images, cleaned_labels = load_images_and_labels(dirty_img_path, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n",
      "Confusion Matrix:\n",
      "[[45  0]\n",
      " [ 6  3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming all HOG features have the same length, let's say `hog_feature_length`\n",
    "hog_feature_length = len(polluted_images[0])\n",
    "\n",
    "# Pad or truncate HOG features to ensure a fixed length\n",
    "def pad_or_truncate(features, target_length):\n",
    "    return [feat[:target_length] if len(feat) >= target_length else np.pad(feat, (0, target_length - len(feat)), 'constant') for feat in features]\n",
    "\n",
    "# Combine data and labels\n",
    "all_images = np.vstack((pad_or_truncate(polluted_images, hog_feature_length), \n",
    "                        pad_or_truncate(cleaned_images, hog_feature_length)))\n",
    "all_labels = np.hstack((polluted_labels, cleaned_labels))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_images, all_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Use a pipeline to standardize the data and train the SVM\n",
    "svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "confusion_mat = confusion_matrix(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (Polluted): [0.07357159 0.0278003  0.03820825 ... 0.04888614 0.03253084 0.03341326]\n",
      "Standard Deviation (Polluted): [0.08344233 0.04968844 0.06615634 ... 0.07368243 0.065941   0.06824429]\n",
      "Mean (Cleaned): [0.11285578 0.04422699 0.05737951 ... 0.07222779 0.05454952 0.05758679]\n",
      "Standard Deviation (Cleaned): [0.0852906  0.0499645  0.06444214 ... 0.06884036 0.05755687 0.0629661 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming all HOG features have the same length, let's say `hog_feature_length`\n",
    "hog_feature_length = len(polluted_images[0])\n",
    "\n",
    "# Pad or truncate HOG features to ensure a fixed length\n",
    "def pad_or_truncate(features, target_length):\n",
    "    return [feat[:target_length] if len(feat) >= target_length else np.pad(feat, (0, target_length - len(feat)), 'constant') for feat in features]\n",
    "\n",
    "# Pad or truncate features to ensure consistent length\n",
    "padded_polluted_images = pad_or_truncate(polluted_images, hog_feature_length)\n",
    "padded_cleaned_images = pad_or_truncate(cleaned_images, hog_feature_length)\n",
    "\n",
    "# Calculate mean and standard deviation for each feature\n",
    "mean_polluted = np.mean(padded_polluted_images, axis=0)\n",
    "std_polluted = np.std(padded_polluted_images, axis=0)\n",
    "\n",
    "mean_cleaned = np.mean(padded_cleaned_images, axis=0)\n",
    "std_cleaned = np.std(padded_cleaned_images, axis=0)\n",
    "\n",
    "print(\"Mean (Polluted):\", mean_polluted)\n",
    "print(\"Standard Deviation (Polluted):\", std_polluted)\n",
    "print(\"Mean (Cleaned):\", mean_cleaned)\n",
    "print(\"Standard Deviation (Cleaned):\", std_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
